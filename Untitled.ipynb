{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967819bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import keras.models\n",
    "from keras.layers import *\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565afbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21258</th>\n",
       "      <td>4</td>\n",
       "      <td>106.957877</td>\n",
       "      <td>53.095769</td>\n",
       "      <td>82.515384</td>\n",
       "      <td>43.135565</td>\n",
       "      <td>1.177145</td>\n",
       "      <td>1.254119</td>\n",
       "      <td>146.88130</td>\n",
       "      <td>15.504479</td>\n",
       "      <td>65.764081</td>\n",
       "      <td>...</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.223710</td>\n",
       "      <td>3.519911</td>\n",
       "      <td>1.377820</td>\n",
       "      <td>0.913658</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168889</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.496904</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21259</th>\n",
       "      <td>5</td>\n",
       "      <td>92.266740</td>\n",
       "      <td>49.021367</td>\n",
       "      <td>64.812662</td>\n",
       "      <td>32.867748</td>\n",
       "      <td>1.323287</td>\n",
       "      <td>1.571630</td>\n",
       "      <td>188.38390</td>\n",
       "      <td>7.353333</td>\n",
       "      <td>69.232655</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>2.168944</td>\n",
       "      <td>2.038991</td>\n",
       "      <td>1.594167</td>\n",
       "      <td>1.337246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.212959</td>\n",
       "      <td>122.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>95.609104</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>95.464320</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>53.041104</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>...</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>4.781762</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.450561</td>\n",
       "      <td>1</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21261</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>97.095602</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>96.901083</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>31.115202</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>...</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>4.665819</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.577601</td>\n",
       "      <td>1</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21262</th>\n",
       "      <td>3</td>\n",
       "      <td>87.468333</td>\n",
       "      <td>86.858500</td>\n",
       "      <td>82.555758</td>\n",
       "      <td>80.458722</td>\n",
       "      <td>1.041270</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>71.75500</td>\n",
       "      <td>43.144000</td>\n",
       "      <td>29.905282</td>\n",
       "      <td>...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.762203</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>0.970116</td>\n",
       "      <td>3</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21263 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                       4         88.944468             57.862692   \n",
       "1                       5         92.729214             58.518416   \n",
       "2                       4         88.944468             57.885242   \n",
       "3                       4         88.944468             57.873967   \n",
       "4                       4         88.944468             57.840143   \n",
       "...                   ...               ...                   ...   \n",
       "21258                   4        106.957877             53.095769   \n",
       "21259                   5         92.266740             49.021367   \n",
       "21260                   2         99.663190             95.609104   \n",
       "21261                   2         99.663190             97.095602   \n",
       "21262                   3         87.468333             86.858500   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0              66.361592              36.116612             1.181795   \n",
       "1              73.132787              36.396602             1.449309   \n",
       "2              66.361592              36.122509             1.181795   \n",
       "3              66.361592              36.119560             1.181795   \n",
       "4              66.361592              36.110716             1.181795   \n",
       "...                  ...                    ...                  ...   \n",
       "21258          82.515384              43.135565             1.177145   \n",
       "21259          64.812662              32.867748             1.323287   \n",
       "21260          99.433882              95.464320             0.690847   \n",
       "21261          99.433882              96.901083             0.690847   \n",
       "21262          82.555758              80.458722             1.041270   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                     1.062396          122.90607              31.794921   \n",
       "1                     1.057755          122.90607              36.161939   \n",
       "2                     0.975980          122.90607              35.741099   \n",
       "3                     1.022291          122.90607              33.768010   \n",
       "4                     1.129224          122.90607              27.848743   \n",
       "...                        ...                ...                    ...   \n",
       "21258                 1.254119          146.88130              15.504479   \n",
       "21259                 1.571630          188.38390               7.353333   \n",
       "21260                 0.530198           13.51362              53.041104   \n",
       "21261                 0.640883           13.51362              31.115202   \n",
       "21262                 0.895229           71.75500              43.144000   \n",
       "\n",
       "       std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
       "0            51.968828  ...          2.257143       2.213364   \n",
       "1            47.094633  ...          2.257143       1.888175   \n",
       "2            51.968828  ...          2.271429       2.213364   \n",
       "3            51.968828  ...          2.264286       2.213364   \n",
       "4            51.968828  ...          2.242857       2.213364   \n",
       "...                ...  ...               ...            ...   \n",
       "21258        65.764081  ...          3.555556       3.223710   \n",
       "21259        69.232655  ...          2.047619       2.168944   \n",
       "21260         6.756810  ...          4.800000       4.472136   \n",
       "21261         6.756810  ...          4.690000       4.472136   \n",
       "21262        29.905282  ...          4.500000       4.762203   \n",
       "\n",
       "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "0               2.219783         1.368922             1.066221              1   \n",
       "1               2.210679         1.557113             1.047221              2   \n",
       "2               2.232679         1.368922             1.029175              1   \n",
       "3               2.226222         1.368922             1.048834              1   \n",
       "4               2.206963         1.368922             1.096052              1   \n",
       "...                  ...              ...                  ...            ...   \n",
       "21258           3.519911         1.377820             0.913658              1   \n",
       "21259           2.038991         1.594167             1.337246              1   \n",
       "21260           4.781762         0.686962             0.450561              1   \n",
       "21261           4.665819         0.686962             0.577601              1   \n",
       "21262           4.242641         1.054920             0.970116              3   \n",
       "\n",
       "       wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp  \n",
       "0               1.085714     0.433013         0.437059          29.00  \n",
       "1               1.128571     0.632456         0.468606          26.00  \n",
       "2               1.114286     0.433013         0.444697          19.00  \n",
       "3               1.100000     0.433013         0.440952          22.00  \n",
       "4               1.057143     0.433013         0.428809          23.00  \n",
       "...                  ...          ...              ...            ...  \n",
       "21258           2.168889     0.433013         0.496904           2.44  \n",
       "21259           0.904762     0.400000         0.212959         122.10  \n",
       "21260           3.200000     0.500000         0.400000           1.98  \n",
       "21261           2.210000     0.500000         0.462493           1.84  \n",
       "21262           1.800000     1.414214         1.500000          12.80  \n",
       "\n",
       "[21263 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f524eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicated rows:\n",
      " 70\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21193 entries, 0 to 21262\n",
      "Data columns (total 82 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   number_of_elements               21193 non-null  int64  \n",
      " 1   mean_atomic_mass                 21193 non-null  float64\n",
      " 2   wtd_mean_atomic_mass             21193 non-null  float64\n",
      " 3   gmean_atomic_mass                21193 non-null  float64\n",
      " 4   wtd_gmean_atomic_mass            21193 non-null  float64\n",
      " 5   entropy_atomic_mass              21193 non-null  float64\n",
      " 6   wtd_entropy_atomic_mass          21193 non-null  float64\n",
      " 7   range_atomic_mass                21193 non-null  float64\n",
      " 8   wtd_range_atomic_mass            21193 non-null  float64\n",
      " 9   std_atomic_mass                  21193 non-null  float64\n",
      " 10  wtd_std_atomic_mass              21193 non-null  float64\n",
      " 11  mean_fie                         21193 non-null  float64\n",
      " 12  wtd_mean_fie                     21193 non-null  float64\n",
      " 13  gmean_fie                        21193 non-null  float64\n",
      " 14  wtd_gmean_fie                    21193 non-null  float64\n",
      " 15  entropy_fie                      21193 non-null  float64\n",
      " 16  wtd_entropy_fie                  21193 non-null  float64\n",
      " 17  range_fie                        21193 non-null  float64\n",
      " 18  wtd_range_fie                    21193 non-null  float64\n",
      " 19  std_fie                          21193 non-null  float64\n",
      " 20  wtd_std_fie                      21193 non-null  float64\n",
      " 21  mean_atomic_radius               21193 non-null  float64\n",
      " 22  wtd_mean_atomic_radius           21193 non-null  float64\n",
      " 23  gmean_atomic_radius              21193 non-null  float64\n",
      " 24  wtd_gmean_atomic_radius          21193 non-null  float64\n",
      " 25  entropy_atomic_radius            21193 non-null  float64\n",
      " 26  wtd_entropy_atomic_radius        21193 non-null  float64\n",
      " 27  range_atomic_radius              21193 non-null  int64  \n",
      " 28  wtd_range_atomic_radius          21193 non-null  float64\n",
      " 29  std_atomic_radius                21193 non-null  float64\n",
      " 30  wtd_std_atomic_radius            21193 non-null  float64\n",
      " 31  mean_Density                     21193 non-null  float64\n",
      " 32  wtd_mean_Density                 21193 non-null  float64\n",
      " 33  gmean_Density                    21193 non-null  float64\n",
      " 34  wtd_gmean_Density                21193 non-null  float64\n",
      " 35  entropy_Density                  21193 non-null  float64\n",
      " 36  wtd_entropy_Density              21193 non-null  float64\n",
      " 37  range_Density                    21193 non-null  float64\n",
      " 38  wtd_range_Density                21193 non-null  float64\n",
      " 39  std_Density                      21193 non-null  float64\n",
      " 40  wtd_std_Density                  21193 non-null  float64\n",
      " 41  mean_ElectronAffinity            21193 non-null  float64\n",
      " 42  wtd_mean_ElectronAffinity        21193 non-null  float64\n",
      " 43  gmean_ElectronAffinity           21193 non-null  float64\n",
      " 44  wtd_gmean_ElectronAffinity       21193 non-null  float64\n",
      " 45  entropy_ElectronAffinity         21193 non-null  float64\n",
      " 46  wtd_entropy_ElectronAffinity     21193 non-null  float64\n",
      " 47  range_ElectronAffinity           21193 non-null  float64\n",
      " 48  wtd_range_ElectronAffinity       21193 non-null  float64\n",
      " 49  std_ElectronAffinity             21193 non-null  float64\n",
      " 50  wtd_std_ElectronAffinity         21193 non-null  float64\n",
      " 51  mean_FusionHeat                  21193 non-null  float64\n",
      " 52  wtd_mean_FusionHeat              21193 non-null  float64\n",
      " 53  gmean_FusionHeat                 21193 non-null  float64\n",
      " 54  wtd_gmean_FusionHeat             21193 non-null  float64\n",
      " 55  entropy_FusionHeat               21193 non-null  float64\n",
      " 56  wtd_entropy_FusionHeat           21193 non-null  float64\n",
      " 57  range_FusionHeat                 21193 non-null  float64\n",
      " 58  wtd_range_FusionHeat             21193 non-null  float64\n",
      " 59  std_FusionHeat                   21193 non-null  float64\n",
      " 60  wtd_std_FusionHeat               21193 non-null  float64\n",
      " 61  mean_ThermalConductivity         21193 non-null  float64\n",
      " 62  wtd_mean_ThermalConductivity     21193 non-null  float64\n",
      " 63  gmean_ThermalConductivity        21193 non-null  float64\n",
      " 64  wtd_gmean_ThermalConductivity    21193 non-null  float64\n",
      " 65  entropy_ThermalConductivity      21193 non-null  float64\n",
      " 66  wtd_entropy_ThermalConductivity  21193 non-null  float64\n",
      " 67  range_ThermalConductivity        21193 non-null  float64\n",
      " 68  wtd_range_ThermalConductivity    21193 non-null  float64\n",
      " 69  std_ThermalConductivity          21193 non-null  float64\n",
      " 70  wtd_std_ThermalConductivity      21193 non-null  float64\n",
      " 71  mean_Valence                     21193 non-null  float64\n",
      " 72  wtd_mean_Valence                 21193 non-null  float64\n",
      " 73  gmean_Valence                    21193 non-null  float64\n",
      " 74  wtd_gmean_Valence                21193 non-null  float64\n",
      " 75  entropy_Valence                  21193 non-null  float64\n",
      " 76  wtd_entropy_Valence              21193 non-null  float64\n",
      " 77  range_Valence                    21193 non-null  int64  \n",
      " 78  wtd_range_Valence                21193 non-null  float64\n",
      " 79  std_Valence                      21193 non-null  float64\n",
      " 80  wtd_std_Valence                  21193 non-null  float64\n",
      " 81  critical_temp                    21193 non-null  float64\n",
      "dtypes: float64(79), int64(3)\n",
      "memory usage: 13.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of duplicated rows:\\n\",data.duplicated().sum())\n",
    "data.drop_duplicates(inplace=True)\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149cf227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dimensions after pre-processing: (21193, 82)\n"
     ]
    }
   ],
   "source": [
    "data_dummies=pd.get_dummies(data,drop_first=True)\n",
    "#shape of the data\n",
    "print(\"\\nThe dimensions after pre-processing:\",data_dummies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da71fd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['number_of_elements', 'mean_atomic_mass', 'wtd_mean_atomic_mass',\n",
      "       'gmean_atomic_mass', 'wtd_gmean_atomic_mass', 'entropy_atomic_mass',\n",
      "       'wtd_entropy_atomic_mass', 'range_atomic_mass', 'wtd_range_atomic_mass',\n",
      "       'std_atomic_mass', 'wtd_std_atomic_mass', 'mean_fie', 'wtd_mean_fie',\n",
      "       'gmean_fie', 'wtd_gmean_fie', 'entropy_fie', 'wtd_entropy_fie',\n",
      "       'range_fie', 'wtd_range_fie', 'std_fie', 'wtd_std_fie',\n",
      "       'mean_atomic_radius', 'wtd_mean_atomic_radius', 'gmean_atomic_radius',\n",
      "       'wtd_gmean_atomic_radius', 'entropy_atomic_radius',\n",
      "       'wtd_entropy_atomic_radius', 'range_atomic_radius',\n",
      "       'wtd_range_atomic_radius', 'std_atomic_radius', 'wtd_std_atomic_radius',\n",
      "       'mean_Density', 'wtd_mean_Density', 'gmean_Density',\n",
      "       'wtd_gmean_Density', 'entropy_Density', 'wtd_entropy_Density',\n",
      "       'range_Density', 'wtd_range_Density', 'std_Density', 'wtd_std_Density',\n",
      "       'mean_ElectronAffinity', 'wtd_mean_ElectronAffinity',\n",
      "       'gmean_ElectronAffinity', 'wtd_gmean_ElectronAffinity',\n",
      "       'entropy_ElectronAffinity', 'wtd_entropy_ElectronAffinity',\n",
      "       'range_ElectronAffinity', 'wtd_range_ElectronAffinity',\n",
      "       'std_ElectronAffinity', 'wtd_std_ElectronAffinity', 'mean_FusionHeat',\n",
      "       'wtd_mean_FusionHeat', 'gmean_FusionHeat', 'wtd_gmean_FusionHeat',\n",
      "       'entropy_FusionHeat', 'wtd_entropy_FusionHeat', 'range_FusionHeat',\n",
      "       'wtd_range_FusionHeat', 'std_FusionHeat', 'wtd_std_FusionHeat',\n",
      "       'mean_ThermalConductivity', 'wtd_mean_ThermalConductivity',\n",
      "       'gmean_ThermalConductivity', 'wtd_gmean_ThermalConductivity',\n",
      "       'entropy_ThermalConductivity', 'wtd_entropy_ThermalConductivity',\n",
      "       'range_ThermalConductivity', 'wtd_range_ThermalConductivity',\n",
      "       'std_ThermalConductivity', 'wtd_std_ThermalConductivity',\n",
      "       'mean_Valence', 'wtd_mean_Valence', 'gmean_Valence',\n",
      "       'wtd_gmean_Valence', 'entropy_Valence', 'wtd_entropy_Valence',\n",
      "       'range_Valence', 'wtd_range_Valence', 'std_Valence', 'wtd_std_Valence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X=data_dummies.drop(['critical_temp'],axis=1)\n",
    "feature_name=X.columns\n",
    "print(feature_name)\n",
    "Y=data_dummies['critical_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4fd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4983372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(14835, 81)\n"
     ]
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "scaled_X_train=scaler.fit_transform(X_train)\n",
    "scaled_X_test=scaler.transform(X_test)\n",
    "print(type(scaled_X_train))\n",
    "print(scaled_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2d095b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The explained variance ratios are:\n",
      " [0.38891125 0.1035418  0.09632024 0.07952354 0.05840235 0.03831443\n",
      " 0.03634343 0.03093011 0.02378442 0.01969829 0.01824705 0.01463564]\n",
      "\n",
      "The total variance in the data is : 0.9086525627037385\n",
      "\n",
      "The number of components: 12\n"
     ]
    }
   ],
   "source": [
    "pca=PCA(0.90)\n",
    "train_data=pca.fit_transform(scaled_X_train)\n",
    "test_data=pca.transform(scaled_X_test)\n",
    "\n",
    "print(\"The explained variance ratios are:\\n\",pca.explained_variance_ratio_)\n",
    "print(\"\\nThe total variance in the data is :\",pca.explained_variance_ratio_.sum())\n",
    "print(\"\\nThe number of components:\",pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0565e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1255      76.80\n",
      "10052      9.95\n",
      "12590      5.20\n",
      "15374      0.28\n",
      "19039    137.40\n",
      "9777      23.60\n",
      "17576    100.00\n",
      "18490     36.90\n",
      "9380      24.00\n",
      "3702     107.00\n",
      "Name: critical_temp, dtype: float64\n",
      "[59.44340463 50.57305378 -0.39225684 -1.93884884 70.25289946 38.29409726\n",
      " 78.54912415 24.03585198 44.66399918 75.8181192 ]\n",
      "The RMSE is : 22.287600720879738\n",
      "The R2 score: 0.5830086084353328\n"
     ]
    }
   ],
   "source": [
    "linear_model=LinearRegression()\n",
    "linear_model.fit(train_data,Y_train)\n",
    "Y_predicted=linear_model.predict(test_data)\n",
    "print(Y_test.iloc[5:15,])\n",
    "print(Y_predicted[5:15])\n",
    "\n",
    "\n",
    "print(\"The RMSE is :\",rmse)\n",
    "print(\"The R2 score:\",r2_score(Y_test,Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb56c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 10, 'n_estimators': 100}\n",
      "Best score 0.8673523325539361\n",
      "Best estimator RandomForestRegressor(max_depth=10, verbose=1)\n",
      "CV Results    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       2.345219      0.042349         0.007218        0.000433   \n",
      "1       4.690527      0.089494         0.013961        0.000899   \n",
      "2       3.152250      0.028894         0.009572        0.000847   \n",
      "3       6.230981      0.058275         0.017773        0.000386   \n",
      "4       4.236804      0.053659         0.013742        0.000345   \n",
      "5       8.421443      0.049118         0.025549        0.001192   \n",
      "\n",
      "  param_max_depth param_n_estimators                                  params  \\\n",
      "0               5                 50    {'max_depth': 5, 'n_estimators': 50}   \n",
      "1               5                100   {'max_depth': 5, 'n_estimators': 100}   \n",
      "2               7                 50    {'max_depth': 7, 'n_estimators': 50}   \n",
      "3               7                100   {'max_depth': 7, 'n_estimators': 100}   \n",
      "4              10                 50   {'max_depth': 10, 'n_estimators': 50}   \n",
      "5              10                100  {'max_depth': 10, 'n_estimators': 100}   \n",
      "\n",
      "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0           0.774818           0.759075           0.774422           0.759407   \n",
      "1           0.777221           0.761249           0.776264           0.759393   \n",
      "2           0.819664           0.820696           0.829354           0.811616   \n",
      "3           0.820344           0.821739           0.830212           0.813737   \n",
      "4           0.861932           0.873527           0.877929           0.857645   \n",
      "5           0.862317           0.876694           0.876073           0.861032   \n",
      "\n",
      "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0           0.752584         0.764061        0.008959                6  \n",
      "1           0.753959         0.765617        0.009399                5  \n",
      "2           0.810209         0.818308        0.006927                4  \n",
      "3           0.810299         0.819266        0.006900                3  \n",
      "4           0.858698         0.865946        0.008229                2  \n",
      "5           0.860646         0.867352        0.007397                1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "rf_cv=RandomForestRegressor(verbose=1)\n",
    "params={'n_estimators':[50,100],\n",
    "        'max_depth':[5,7,10]}\n",
    "gs_cv=GridSearchCV(rf_cv,params,cv=5)\n",
    "gs_cv.fit(train_data,Y_train)\n",
    "print(\"Best params:\",gs_cv.best_params_)\n",
    "print(\"Best score\",gs_cv.best_score_)\n",
    "print(\"Best estimator\",gs_cv.best_estimator_)\n",
    "grid_results=pd.DataFrame(gs_cv.cv_results_)\n",
    "print(\"CV Results\",grid_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0c22578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE RMSE OF RF IS: 12.615674254265597\n",
      "The oob score: 0.8705528253923351\n",
      "The R2 score: 0.5830086084353328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "random_forest=RandomForestRegressor(n_estimators=100,oob_score=True,random_state=21,verbose=1,max_depth=10)\n",
    "random_forest.fit(train_data,Y_train)\n",
    "RF_predicted=random_forest.predict(test_data)\n",
    "RF_RMSE=np.sqrt(mean_squared_error(Y_test,RF_predicted))\n",
    "print(\"THE RMSE OF RF IS:\",RF_RMSE)\n",
    "print(\"The oob score:\",random_forest.oob_score_)\n",
    "print(\"The R2 score:\",r2_score(Y_test,Y_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a4c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
