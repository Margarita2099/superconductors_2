{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20460463",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78788423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "# to select the features\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "from tabulate import tabulate\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b6f02",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d87197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>wtd_std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>53.622535</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>53.979870</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>53.656268</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>53.639405</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>53.588771</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21188</th>\n",
       "      <td>106.957877</td>\n",
       "      <td>53.095769</td>\n",
       "      <td>82.515384</td>\n",
       "      <td>43.135565</td>\n",
       "      <td>1.177145</td>\n",
       "      <td>1.254119</td>\n",
       "      <td>146.88130</td>\n",
       "      <td>15.504479</td>\n",
       "      <td>65.764081</td>\n",
       "      <td>43.202659</td>\n",
       "      <td>...</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.223710</td>\n",
       "      <td>3.519911</td>\n",
       "      <td>1.377820</td>\n",
       "      <td>0.913658</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168889</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.496904</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21189</th>\n",
       "      <td>92.266740</td>\n",
       "      <td>49.021367</td>\n",
       "      <td>64.812662</td>\n",
       "      <td>32.867748</td>\n",
       "      <td>1.323287</td>\n",
       "      <td>1.571630</td>\n",
       "      <td>188.38390</td>\n",
       "      <td>7.353333</td>\n",
       "      <td>69.232655</td>\n",
       "      <td>50.148287</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>2.168944</td>\n",
       "      <td>2.038991</td>\n",
       "      <td>1.594167</td>\n",
       "      <td>1.337246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.212959</td>\n",
       "      <td>122.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21190</th>\n",
       "      <td>99.663190</td>\n",
       "      <td>95.609104</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>95.464320</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>53.041104</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>5.405448</td>\n",
       "      <td>...</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>4.781762</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.450561</td>\n",
       "      <td>1</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21191</th>\n",
       "      <td>99.663190</td>\n",
       "      <td>97.095602</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>96.901083</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>31.115202</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>6.249958</td>\n",
       "      <td>...</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>4.665819</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.577601</td>\n",
       "      <td>1</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21192</th>\n",
       "      <td>87.468333</td>\n",
       "      <td>86.858500</td>\n",
       "      <td>82.555758</td>\n",
       "      <td>80.458722</td>\n",
       "      <td>1.041270</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>71.75500</td>\n",
       "      <td>43.144000</td>\n",
       "      <td>29.905282</td>\n",
       "      <td>33.927941</td>\n",
       "      <td>...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.762203</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>0.970116</td>\n",
       "      <td>3</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21193 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_atomic_mass  wtd_mean_atomic_mass  gmean_atomic_mass  \\\n",
       "0             88.944468             57.862692          66.361592   \n",
       "1             92.729214             58.518416          73.132787   \n",
       "2             88.944468             57.885242          66.361592   \n",
       "3             88.944468             57.873967          66.361592   \n",
       "4             88.944468             57.840143          66.361592   \n",
       "...                 ...                   ...                ...   \n",
       "21188        106.957877             53.095769          82.515384   \n",
       "21189         92.266740             49.021367          64.812662   \n",
       "21190         99.663190             95.609104          99.433882   \n",
       "21191         99.663190             97.095602          99.433882   \n",
       "21192         87.468333             86.858500          82.555758   \n",
       "\n",
       "       wtd_gmean_atomic_mass  entropy_atomic_mass  wtd_entropy_atomic_mass  \\\n",
       "0                  36.116612             1.181795                 1.062396   \n",
       "1                  36.396602             1.449309                 1.057755   \n",
       "2                  36.122509             1.181795                 0.975980   \n",
       "3                  36.119560             1.181795                 1.022291   \n",
       "4                  36.110716             1.181795                 1.129224   \n",
       "...                      ...                  ...                      ...   \n",
       "21188              43.135565             1.177145                 1.254119   \n",
       "21189              32.867748             1.323287                 1.571630   \n",
       "21190              95.464320             0.690847                 0.530198   \n",
       "21191              96.901083             0.690847                 0.640883   \n",
       "21192              80.458722             1.041270                 0.895229   \n",
       "\n",
       "       range_atomic_mass  wtd_range_atomic_mass  std_atomic_mass  \\\n",
       "0              122.90607              31.794921        51.968828   \n",
       "1              122.90607              36.161939        47.094633   \n",
       "2              122.90607              35.741099        51.968828   \n",
       "3              122.90607              33.768010        51.968828   \n",
       "4              122.90607              27.848743        51.968828   \n",
       "...                  ...                    ...              ...   \n",
       "21188          146.88130              15.504479        65.764081   \n",
       "21189          188.38390               7.353333        69.232655   \n",
       "21190           13.51362              53.041104         6.756810   \n",
       "21191           13.51362              31.115202         6.756810   \n",
       "21192           71.75500              43.144000        29.905282   \n",
       "\n",
       "       wtd_std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
       "0                53.622535  ...          2.257143       2.213364   \n",
       "1                53.979870  ...          2.257143       1.888175   \n",
       "2                53.656268  ...          2.271429       2.213364   \n",
       "3                53.639405  ...          2.264286       2.213364   \n",
       "4                53.588771  ...          2.242857       2.213364   \n",
       "...                    ...  ...               ...            ...   \n",
       "21188            43.202659  ...          3.555556       3.223710   \n",
       "21189            50.148287  ...          2.047619       2.168944   \n",
       "21190             5.405448  ...          4.800000       4.472136   \n",
       "21191             6.249958  ...          4.690000       4.472136   \n",
       "21192            33.927941  ...          4.500000       4.762203   \n",
       "\n",
       "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "0               2.219783         1.368922             1.066221              1   \n",
       "1               2.210679         1.557113             1.047221              2   \n",
       "2               2.232679         1.368922             1.029175              1   \n",
       "3               2.226222         1.368922             1.048834              1   \n",
       "4               2.206963         1.368922             1.096052              1   \n",
       "...                  ...              ...                  ...            ...   \n",
       "21188           3.519911         1.377820             0.913658              1   \n",
       "21189           2.038991         1.594167             1.337246              1   \n",
       "21190           4.781762         0.686962             0.450561              1   \n",
       "21191           4.665819         0.686962             0.577601              1   \n",
       "21192           4.242641         1.054920             0.970116              3   \n",
       "\n",
       "       wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp  \n",
       "0               1.085714     0.433013         0.437059          29.00  \n",
       "1               1.128571     0.632456         0.468606          26.00  \n",
       "2               1.114286     0.433013         0.444697          19.00  \n",
       "3               1.100000     0.433013         0.440952          22.00  \n",
       "4               1.057143     0.433013         0.428809          23.00  \n",
       "...                  ...          ...              ...            ...  \n",
       "21188           2.168889     0.433013         0.496904           2.44  \n",
       "21189           0.904762     0.400000         0.212959         122.10  \n",
       "21190           3.200000     0.500000         0.400000           1.98  \n",
       "21191           2.210000     0.500000         0.462493           1.84  \n",
       "21192           1.800000     1.414214         1.500000          12.80  \n",
       "\n",
       "[21193 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../train_1.csv'\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4192c51",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e775574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14835, 80), (6358, 80))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = data.iloc[:, 0:-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0,\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a6c23",
   "metadata": {},
   "source": [
    "# Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7172cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ec268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   22.3s finished\n",
      "Features: 1/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:   32.1s finished\n",
      "Features: 2/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:   45.6s finished\n",
      "Features: 3/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:   57.5s finished\n",
      "Features: 4/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:  1.1min finished\n",
      "Features: 5/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  1.2min finished\n",
      "Features: 6/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:  1.3min finished\n",
      "Features: 7/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:  1.6min finished\n",
      "Features: 8/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.7min finished\n",
      "Features: 9/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:  1.7min finished\n",
      "Features: 10/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  1.8min finished\n",
      "Features: 11/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:  2.0min finished\n",
      "Features: 12/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:  2.1min finished\n",
      "Features: 13/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:  2.1min finished\n",
      "Features: 14/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  2.1min finished\n",
      "Features: 15/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  2.2min finished\n",
      "Features: 16/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  2.5min finished\n",
      "Features: 17/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  2.6min finished\n",
      "Features: 18/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:  2.6min finished\n",
      "Features: 19/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:  2.9min finished\n",
      "Features: 20/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.0min finished\n",
      "Features: 21/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:  3.0min finished\n",
      "Features: 22/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:  3.3min finished\n",
      "Features: 23/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:  3.3min finished\n",
      "Features: 24/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:  3.4min finished\n",
      "Features: 25/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:  3.4min finished\n",
      "Features: 26/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  3.6min finished\n",
      "Features: 27/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:  3.7min finished\n",
      "Features: 28/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:  3.7min finished\n",
      "Features: 29/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:  3.8min finished\n",
      "Features: 30/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  3.7min finished\n",
      "Features: 31/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  3.7min finished\n",
      "Features: 32/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  3.7min finished\n",
      "Features: 33/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:  3.9min finished\n",
      "Features: 34/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:  3.8min finished\n",
      "Features: 35/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  3.7min finished\n",
      "Features: 36/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:  3.8min finished\n",
      "Features: 37/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:  3.9min finished\n",
      "Features: 38/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:  3.9min finished\n",
      "Features: 39/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:  3.9min finished\n",
      "Features: 40/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  4.0min finished\n",
      "Features: 41/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  4.0min finished\n",
      "Features: 42/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  4.0min finished\n",
      "Features: 43/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  3.9min finished\n",
      "Features: 44/45[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  3.9min finished\n",
      "Features: 45/45"
     ]
    }
   ],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=RandomForestRegressor(n_estimators=5, random_state=0),\n",
    "    k_features=45,  # the number of features to retain\n",
    "    forward=True, # the direction of  the search\n",
    "    verbose=1,  # print out intermediate steps\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    ")\n",
    "\n",
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb40075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mean_atomic_mass',\n",
       " 'wtd_mean_atomic_mass',\n",
       " 'gmean_atomic_mass',\n",
       " 'wtd_gmean_atomic_mass',\n",
       " 'entropy_atomic_mass',\n",
       " 'range_atomic_mass',\n",
       " 'wtd_std_atomic_mass',\n",
       " 'mean_fie',\n",
       " 'wtd_mean_fie',\n",
       " 'gmean_fie',\n",
       " 'wtd_gmean_fie',\n",
       " 'entropy_fie',\n",
       " 'range_fie',\n",
       " 'std_fie',\n",
       " 'wtd_std_fie',\n",
       " 'mean_atomic_radius',\n",
       " 'gmean_atomic_radius',\n",
       " 'entropy_atomic_radius',\n",
       " 'wtd_std_atomic_radius',\n",
       " 'mean_Density',\n",
       " 'gmean_Density',\n",
       " 'entropy_Density',\n",
       " 'range_Density',\n",
       " 'wtd_std_Density',\n",
       " 'wtd_mean_ElectronAffinity',\n",
       " 'gmean_ElectronAffinity',\n",
       " 'range_ElectronAffinity',\n",
       " 'std_ElectronAffinity',\n",
       " 'mean_FusionHeat',\n",
       " 'gmean_FusionHeat',\n",
       " 'entropy_FusionHeat',\n",
       " 'range_FusionHeat',\n",
       " 'wtd_std_FusionHeat',\n",
       " 'mean_ThermalConductivity',\n",
       " 'gmean_ThermalConductivity',\n",
       " 'wtd_gmean_ThermalConductivity',\n",
       " 'wtd_entropy_ThermalConductivity',\n",
       " 'wtd_range_ThermalConductivity',\n",
       " 'std_ThermalConductivity',\n",
       " 'mean_Valence',\n",
       " 'wtd_mean_Valence',\n",
       " 'gmean_Valence',\n",
       " 'entropy_Valence',\n",
       " 'range_Valence',\n",
       " 'std_Valence')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f94704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76.5177175 , 87.41587988, 59.31009613, ...,  1.36892236,\n",
       "         1.        ,  0.4330127 ],\n",
       "       [67.4025    , 67.4025    , 66.40422577, ...,  0.63651417,\n",
       "         3.        ,  1.5       ],\n",
       "       [89.33718   , 82.94251571, 70.56064655, ...,  1.56495725,\n",
       "         2.        ,  0.8       ],\n",
       "       ...,\n",
       "       [90.30468   , 85.92509   , 70.97001973, ...,  1.56495725,\n",
       "         2.        ,  0.8       ],\n",
       "       [63.45766667, 68.46450649, 62.15993083, ...,  1.01140426,\n",
       "         4.        ,  1.63299316],\n",
       "       [69.17125   , 51.77830016, 54.8727651 , ...,  1.5941667 ,\n",
       "         1.        ,  0.4       ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t = sfs.transform(X_train)\n",
    "X_test_t = sfs.transform(X_test)\n",
    "\n",
    "X_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07865cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14835, 45), (6358, 45))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape, X_test_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec746bf7",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8549bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_sc= min_max_scaler.fit_transform(X_train_t)\n",
    "\n",
    "X_test_sc=min_max_scaler.fit_transform(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d26aaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "y_train_sc = scaler.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_test_sc = scaler.fit_transform(y_test.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20b225",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6526d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b5c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error as mae,\n",
    "    r2_score as r2,\n",
    "    mean_absolute_percentage_error as mape,\n",
    "    mean_squared_error as mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67121d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(model, X_train_sc, X_test_sc, y_train_sc, y_test_sc, label):\n",
    "    print(f'Train MAE ({label}):', round(mae(y_train_sc, model.predict(X_train_sc)), 4))\n",
    "    print(f'Test MAE ({label}) :', round(mae(y_test_sc, model.predict(X_test_sc)), 4), '\\n')\n",
    "\n",
    "    print(f'Train R^2 ({label}):', round(r2(y_train_sc, model.predict(X_train_sc)), 4))\n",
    "    print(f'Test R^2 ({label}) :', round(r2(y_test_sc, model.predict(X_test_sc)), 4), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e393e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE (LR_baseline): 0.1044\n",
      "Test MAE (LR_baseline) : 0.1125 \n",
      "\n",
      "Train R^2 (LR_baseline): 0.6839\n",
      "Test R^2 (LR_baseline) : 0.3617 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_baseline = LinearRegression().fit(X_train_sc, y_train_sc)\n",
    "report_metrics(LR_baseline, X_train_sc, X_test_sc, y_train_sc, y_test_sc, 'LR_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e83a344",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54bfab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3ff71c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            fit_time  score_time  neg_mean_squared_error  \\\n",
      "RandomForestRegressor      69.818625    0.033891               -0.004418   \n",
      "XGBRegressor               11.871271    0.003769               -0.004872   \n",
      "KNeighborsRegressor         0.007753    0.088876               -0.006612   \n",
      "LGBMRegressor               1.072925    0.006446               -0.005381   \n",
      "SVR                         8.874920    1.135444               -0.010664   \n",
      "DecisionTreeRegressor       0.927117    0.001469               -0.006998   \n",
      "GradientBoostingRegressor  30.509327    0.002664               -0.008409   \n",
      "\n",
      "                           neg_mean_absolute_error  \n",
      "RandomForestRegressor                    -0.037278  \n",
      "XGBRegressor                             -0.041526  \n",
      "KNeighborsRegressor                      -0.045355  \n",
      "LGBMRegressor                            -0.046402  \n",
      "SVR                                      -0.075414  \n",
      "DecisionTreeRegressor                    -0.043494  \n",
      "GradientBoostingRegressor                -0.062613  \n"
     ]
    }
   ],
   "source": [
    "# Assuming you have defined X_train_sc and y_train_sc\n",
    "\n",
    "list_of_models = [\n",
    "    RandomForestRegressor(),\n",
    "    XGBRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    LGBMRegressor(),\n",
    "    SVR(),\n",
    "    DecisionTreeRegressor(),\n",
    "    GradientBoostingRegressor()\n",
    "]\n",
    "\n",
    "list_of_model_names = [type(x).__name__ for x in list_of_models]\n",
    "cv_results = pd.DataFrame(\n",
    "    data=0.0,\n",
    "    index=list_of_model_names,\n",
    "    columns=['fit_time', 'score_time', 'neg_mean_squared_error', 'neg_mean_absolute_error'])\n",
    "\n",
    "for model in list_of_models:\n",
    "    cv_result = cross_validate(\n",
    "        estimator=model,\n",
    "        X=X_train_sc,\n",
    "        y=y_train_sc,\n",
    "        scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n",
    "        cv=30,\n",
    "        n_jobs=-1)\n",
    "\n",
    "    cv_results.loc[type(model).__name__] = [\n",
    "        np.mean(cv_result['fit_time']),\n",
    "        np.mean(cv_result['score_time']),\n",
    "        np.mean(cv_result['test_neg_mean_squared_error']),\n",
    "        np.mean(cv_result['test_neg_mean_absolute_error'])  # Removed the negative sign here\n",
    "    ]\n",
    "\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31be9a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Margarita\\AppData\\Local\\Temp\\ipykernel_15784\\377911579.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train_sc, y_train_sc)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.008880567450013277\n",
      "Mean Absolute Error (MAE): 0.061649325968687656\n",
      "R-squared (R2): 0.7426886545608502\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_sc, y_train_sc)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_sc)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test_sc, y_pred)\n",
    "mae = mean_absolute_error(y_test_sc, y_pred)\n",
    "r2 = r2_score(y_test_sc, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d4d9141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.009359559656176108\n",
      "Mean Absolute Error (MAE): 0.06263178522982275\n",
      "R-squared (R2): 0.7288100223995191\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train_sc, y_train_sc)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_sc)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test_sc, y_pred)\n",
    "mae = mean_absolute_error(y_test_sc, y_pred)\n",
    "r2 = r2_score(y_test_sc, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"R-squared (R2):\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514c13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
