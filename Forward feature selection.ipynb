{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fec97ce",
   "metadata": {},
   "source": [
    "In forward selection, variables are progressively incorporated into larger and larger subsets. The\n",
    "algorithms start by training all possible single-variable machine learning models. Then, it selects\n",
    "the feature that returned the best performing classifier or regression model. In the second step, it\n",
    "creates machine learning models for all combinations of the features from the previous step with\n",
    "all remaining variables in the data. It selects the pair of features that produce the best performing\n",
    "algorithm. And it continues, adding 1 feature at a time to the feature subset from the previous step\n",
    "until a stopping criteria is met.\n",
    "\n",
    "The feature subsets are nested because they include the feature or features from the previous steps.\n",
    "By progressively evaluating promising features, forward feature selection is more efficient than\n",
    "exhaustive search.\n",
    "\n",
    "Forward feature selection has the advantage that, by starting with smaller feature subsets, it is more\n",
    "computationally efficient than other wrapper methods. However, for this same reason, it does not\n",
    "contemplate feature interactions. Or at least not until sufficient features have been added to the\n",
    "subset.\n",
    "\n",
    "Forward feature selection needs a criteria to stop the search. The most obvious stopping condition\n",
    "is when the performance of the classifier or regression model does not improve beyond a certain\n",
    "\n",
    "threshold. This has the advantage of focusing the search on performance. On the downside, the\n",
    "threshold for improvement is arbitrarily set by the user. Alternatively, we can stop the search after\n",
    "a certain number of features have been selected.\n",
    "\n",
    "In the coming paragraphs, we will implement forwardfeature selection with Scikit-learn and\n",
    "MLXtend. The 2 Python implementations are very similar. Both offer a number of features as\n",
    "stopping criteria. Scikit-learn also offers a threshold on performance improvement as a method to\n",
    "stop the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78788423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "# to select the features\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "import pandas as pd\n",
    "import csv\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "from tabulate import tabulate\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error, r2_score, mean_squared_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d87197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_elements</th>\n",
       "      <th>mean_atomic_mass</th>\n",
       "      <th>wtd_mean_atomic_mass</th>\n",
       "      <th>gmean_atomic_mass</th>\n",
       "      <th>wtd_gmean_atomic_mass</th>\n",
       "      <th>entropy_atomic_mass</th>\n",
       "      <th>wtd_entropy_atomic_mass</th>\n",
       "      <th>range_atomic_mass</th>\n",
       "      <th>wtd_range_atomic_mass</th>\n",
       "      <th>std_atomic_mass</th>\n",
       "      <th>...</th>\n",
       "      <th>wtd_mean_Valence</th>\n",
       "      <th>gmean_Valence</th>\n",
       "      <th>wtd_gmean_Valence</th>\n",
       "      <th>entropy_Valence</th>\n",
       "      <th>wtd_entropy_Valence</th>\n",
       "      <th>range_Valence</th>\n",
       "      <th>wtd_range_Valence</th>\n",
       "      <th>std_Valence</th>\n",
       "      <th>wtd_std_Valence</th>\n",
       "      <th>critical_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.862692</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.116612</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.062396</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>31.794921</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.219783</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.066221</td>\n",
       "      <td>1</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.437059</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>92.729214</td>\n",
       "      <td>58.518416</td>\n",
       "      <td>73.132787</td>\n",
       "      <td>36.396602</td>\n",
       "      <td>1.449309</td>\n",
       "      <td>1.057755</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>36.161939</td>\n",
       "      <td>47.094633</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.888175</td>\n",
       "      <td>2.210679</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>1.047221</td>\n",
       "      <td>2</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.632456</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.885242</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.122509</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>0.975980</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>35.741099</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.232679</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.029175</td>\n",
       "      <td>1</td>\n",
       "      <td>1.114286</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.444697</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.873967</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.119560</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.022291</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>33.768010</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.264286</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.226222</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.048834</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.440952</td>\n",
       "      <td>22.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>88.944468</td>\n",
       "      <td>57.840143</td>\n",
       "      <td>66.361592</td>\n",
       "      <td>36.110716</td>\n",
       "      <td>1.181795</td>\n",
       "      <td>1.129224</td>\n",
       "      <td>122.90607</td>\n",
       "      <td>27.848743</td>\n",
       "      <td>51.968828</td>\n",
       "      <td>...</td>\n",
       "      <td>2.242857</td>\n",
       "      <td>2.213364</td>\n",
       "      <td>2.206963</td>\n",
       "      <td>1.368922</td>\n",
       "      <td>1.096052</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057143</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.428809</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21258</th>\n",
       "      <td>4</td>\n",
       "      <td>106.957877</td>\n",
       "      <td>53.095769</td>\n",
       "      <td>82.515384</td>\n",
       "      <td>43.135565</td>\n",
       "      <td>1.177145</td>\n",
       "      <td>1.254119</td>\n",
       "      <td>146.88130</td>\n",
       "      <td>15.504479</td>\n",
       "      <td>65.764081</td>\n",
       "      <td>...</td>\n",
       "      <td>3.555556</td>\n",
       "      <td>3.223710</td>\n",
       "      <td>3.519911</td>\n",
       "      <td>1.377820</td>\n",
       "      <td>0.913658</td>\n",
       "      <td>1</td>\n",
       "      <td>2.168889</td>\n",
       "      <td>0.433013</td>\n",
       "      <td>0.496904</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21259</th>\n",
       "      <td>5</td>\n",
       "      <td>92.266740</td>\n",
       "      <td>49.021367</td>\n",
       "      <td>64.812662</td>\n",
       "      <td>32.867748</td>\n",
       "      <td>1.323287</td>\n",
       "      <td>1.571630</td>\n",
       "      <td>188.38390</td>\n",
       "      <td>7.353333</td>\n",
       "      <td>69.232655</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>2.168944</td>\n",
       "      <td>2.038991</td>\n",
       "      <td>1.594167</td>\n",
       "      <td>1.337246</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.212959</td>\n",
       "      <td>122.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>95.609104</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>95.464320</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.530198</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>53.041104</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>...</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>4.781762</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.450561</td>\n",
       "      <td>1</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21261</th>\n",
       "      <td>2</td>\n",
       "      <td>99.663190</td>\n",
       "      <td>97.095602</td>\n",
       "      <td>99.433882</td>\n",
       "      <td>96.901083</td>\n",
       "      <td>0.690847</td>\n",
       "      <td>0.640883</td>\n",
       "      <td>13.51362</td>\n",
       "      <td>31.115202</td>\n",
       "      <td>6.756810</td>\n",
       "      <td>...</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>4.665819</td>\n",
       "      <td>0.686962</td>\n",
       "      <td>0.577601</td>\n",
       "      <td>1</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462493</td>\n",
       "      <td>1.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21262</th>\n",
       "      <td>3</td>\n",
       "      <td>87.468333</td>\n",
       "      <td>86.858500</td>\n",
       "      <td>82.555758</td>\n",
       "      <td>80.458722</td>\n",
       "      <td>1.041270</td>\n",
       "      <td>0.895229</td>\n",
       "      <td>71.75500</td>\n",
       "      <td>43.144000</td>\n",
       "      <td>29.905282</td>\n",
       "      <td>...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.762203</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>0.970116</td>\n",
       "      <td>3</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21263 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_of_elements  mean_atomic_mass  wtd_mean_atomic_mass  \\\n",
       "0                       4         88.944468             57.862692   \n",
       "1                       5         92.729214             58.518416   \n",
       "2                       4         88.944468             57.885242   \n",
       "3                       4         88.944468             57.873967   \n",
       "4                       4         88.944468             57.840143   \n",
       "...                   ...               ...                   ...   \n",
       "21258                   4        106.957877             53.095769   \n",
       "21259                   5         92.266740             49.021367   \n",
       "21260                   2         99.663190             95.609104   \n",
       "21261                   2         99.663190             97.095602   \n",
       "21262                   3         87.468333             86.858500   \n",
       "\n",
       "       gmean_atomic_mass  wtd_gmean_atomic_mass  entropy_atomic_mass  \\\n",
       "0              66.361592              36.116612             1.181795   \n",
       "1              73.132787              36.396602             1.449309   \n",
       "2              66.361592              36.122509             1.181795   \n",
       "3              66.361592              36.119560             1.181795   \n",
       "4              66.361592              36.110716             1.181795   \n",
       "...                  ...                    ...                  ...   \n",
       "21258          82.515384              43.135565             1.177145   \n",
       "21259          64.812662              32.867748             1.323287   \n",
       "21260          99.433882              95.464320             0.690847   \n",
       "21261          99.433882              96.901083             0.690847   \n",
       "21262          82.555758              80.458722             1.041270   \n",
       "\n",
       "       wtd_entropy_atomic_mass  range_atomic_mass  wtd_range_atomic_mass  \\\n",
       "0                     1.062396          122.90607              31.794921   \n",
       "1                     1.057755          122.90607              36.161939   \n",
       "2                     0.975980          122.90607              35.741099   \n",
       "3                     1.022291          122.90607              33.768010   \n",
       "4                     1.129224          122.90607              27.848743   \n",
       "...                        ...                ...                    ...   \n",
       "21258                 1.254119          146.88130              15.504479   \n",
       "21259                 1.571630          188.38390               7.353333   \n",
       "21260                 0.530198           13.51362              53.041104   \n",
       "21261                 0.640883           13.51362              31.115202   \n",
       "21262                 0.895229           71.75500              43.144000   \n",
       "\n",
       "       std_atomic_mass  ...  wtd_mean_Valence  gmean_Valence  \\\n",
       "0            51.968828  ...          2.257143       2.213364   \n",
       "1            47.094633  ...          2.257143       1.888175   \n",
       "2            51.968828  ...          2.271429       2.213364   \n",
       "3            51.968828  ...          2.264286       2.213364   \n",
       "4            51.968828  ...          2.242857       2.213364   \n",
       "...                ...  ...               ...            ...   \n",
       "21258        65.764081  ...          3.555556       3.223710   \n",
       "21259        69.232655  ...          2.047619       2.168944   \n",
       "21260         6.756810  ...          4.800000       4.472136   \n",
       "21261         6.756810  ...          4.690000       4.472136   \n",
       "21262        29.905282  ...          4.500000       4.762203   \n",
       "\n",
       "       wtd_gmean_Valence  entropy_Valence  wtd_entropy_Valence  range_Valence  \\\n",
       "0               2.219783         1.368922             1.066221              1   \n",
       "1               2.210679         1.557113             1.047221              2   \n",
       "2               2.232679         1.368922             1.029175              1   \n",
       "3               2.226222         1.368922             1.048834              1   \n",
       "4               2.206963         1.368922             1.096052              1   \n",
       "...                  ...              ...                  ...            ...   \n",
       "21258           3.519911         1.377820             0.913658              1   \n",
       "21259           2.038991         1.594167             1.337246              1   \n",
       "21260           4.781762         0.686962             0.450561              1   \n",
       "21261           4.665819         0.686962             0.577601              1   \n",
       "21262           4.242641         1.054920             0.970116              3   \n",
       "\n",
       "       wtd_range_Valence  std_Valence  wtd_std_Valence  critical_temp  \n",
       "0               1.085714     0.433013         0.437059          29.00  \n",
       "1               1.128571     0.632456         0.468606          26.00  \n",
       "2               1.114286     0.433013         0.444697          19.00  \n",
       "3               1.100000     0.433013         0.440952          22.00  \n",
       "4               1.057143     0.433013         0.428809          23.00  \n",
       "...                  ...          ...              ...            ...  \n",
       "21258           2.168889     0.433013         0.496904           2.44  \n",
       "21259           0.904762     0.400000         0.212959         122.10  \n",
       "21260           3.200000     0.500000         0.400000           1.98  \n",
       "21261           2.210000     0.500000         0.462493           1.84  \n",
       "21262           1.800000     1.414214         1.500000          12.80  \n",
       "\n",
       "[21263 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e775574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14835, 80), (6358, 80))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "data = data.drop(columns=['number_of_elements'])\n",
    "X = data.iloc[:, 0:-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0,\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7172cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4ec268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   18.2s finished\n",
      "Features: 1/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:   26.6s finished\n",
      "Features: 2/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:   38.5s finished\n",
      "Features: 3/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:   50.0s finished\n",
      "Features: 4/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:   55.0s finished\n",
      "Features: 5/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  1.1min finished\n",
      "Features: 6/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:  1.1min finished\n",
      "Features: 7/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:  1.5min finished\n",
      "Features: 8/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.4min finished\n",
      "Features: 9/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:  1.5min finished\n",
      "Features: 10/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:  1.6min finished\n",
      "Features: 11/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:  1.8min finished\n",
      "Features: 12/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:  1.7min finished\n",
      "Features: 13/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:  1.7min finished\n",
      "Features: 14/15[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  1.7min finished\n",
      "Features: 15/15"
     ]
    }
   ],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "sfs = SFS(\n",
    "    estimator=RandomForestRegressor(n_estimators=5, random_state=0),\n",
    "    k_features=15,  # the number of features to retain\n",
    "    forward=True, # the direction of  the search\n",
    "    verbose=1,  # print out intermediate steps\n",
    "    scoring='r2',\n",
    "    cv=3,\n",
    ")\n",
    "\n",
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb40075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mean_atomic_mass',\n",
       " 'wtd_gmean_atomic_mass',\n",
       " 'range_atomic_mass',\n",
       " 'wtd_std_atomic_mass',\n",
       " 'range_fie',\n",
       " 'entropy_atomic_radius',\n",
       " 'entropy_Density',\n",
       " 'range_Density',\n",
       " 'std_ElectronAffinity',\n",
       " 'mean_ThermalConductivity',\n",
       " 'wtd_range_ThermalConductivity',\n",
       " 'mean_Valence',\n",
       " 'wtd_mean_Valence',\n",
       " 'gmean_Valence',\n",
       " 'entropy_Valence')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f94704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76.5177175 ,  65.41137811, 122.90607   , ...,   2.4625    ,\n",
       "          2.21336384,   1.36892236],\n",
       "       [ 67.4025    ,  66.40422577,  23.115     , ...,   4.5       ,\n",
       "          4.24264069,   0.63651417],\n",
       "       [ 89.33718   ,  69.13330879, 124.90825   , ...,   2.17142857,\n",
       "          2.49146188,   1.56495725],\n",
       "       ...,\n",
       "       [ 90.30468   ,  64.31362755, 128.2426    , ...,   2.465     ,\n",
       "          2.49146188,   1.56495725],\n",
       "       [ 63.45766667,  66.73940342,  31.093     , ...,   5.24675325,\n",
       "          3.63424119,   1.01140426],\n",
       "       [ 69.17125   ,  35.42963674, 121.3276    , ...,   2.07103394,\n",
       "          2.16894354,   1.5941667 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t = sfs.transform(X_train)\n",
    "X_test_t = sfs.transform(X_test)\n",
    "\n",
    "X_test_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07865cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
